{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3f438b",
   "metadata": {},
   "source": [
    "# LTsim Use-Case Example: Benchmarking machine learning models\n",
    "\n",
    "The methods in this script include: standardizing data formats across our datasets, sets up the ML models, and calculates case/control AUCs as well as feature-selection AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75758323",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85be6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# from heritability_model_interpretable import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7106a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSum:\n",
    "    \"\"\"Handy class to store all information about each model; primarily useful if running each model in parellel and need to save output\"\"\"\n",
    "    def __init__(self, pset, simnum):\n",
    "        self.pset = pset\n",
    "        self.simnum = int(simnum)\n",
    "\n",
    "        self.data_type = None\n",
    "        self.rho=None\n",
    "        self.pve=None\n",
    "        self.maf_frac=None\n",
    "        self.obs=None\n",
    "        self.k=None\n",
    "        self.overlap=None\n",
    "        self.class_imbalance = 0.5\n",
    "\n",
    "        self.real_interp_auc = {}\n",
    "        self.rand_interp_auc = {}\n",
    "\n",
    "        self.real_class_auc = {}\n",
    "        self.rand_class_auc = {}\n",
    "\n",
    "        self.classification_aucs = {}\n",
    "        ### Return importance scores as well\n",
    "        self.vscores = {}\n",
    "\n",
    "    def populate_pset_vars(self):\n",
    "        # Set up simlation run\n",
    "        sp = self.pset.split('-')\n",
    "\n",
    "        if 'prop_case' in sp:\n",
    "            self.class_imbalance = float(sp[sp.index('prop_case')+1])\n",
    "        if 'rho' in sp:\n",
    "            self.rho = float(sp[sp.index('rho')+1])\n",
    "        if 'pve' in sp:\n",
    "            self.pve = float(sp[sp.index('pve')+1])\n",
    "        if 'maf_frac' in sp:\n",
    "            self.maf_frac = float(sp[sp.index('maf_frac')+1])\n",
    "        if 'obs' in sp:\n",
    "            self.obs = float(sp[sp.index('obs')+1])\n",
    "        if 'k' in sp:\n",
    "            self.k = float(sp[sp.index('k')+1])\n",
    "        if 'ind' in sp:\n",
    "            self.overlap = True\n",
    "        elif 'non_overlap_degree' in sp:\n",
    "            self.overlap = False\n",
    "\n",
    "\n",
    "def split_data(X, y, test_size=0.1, rand_state=5):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=rand_state,\n",
    "                                                    shuffle = True, stratify = y)\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "def train_model(mod_type, train_x, test_x, train_y, test_y, var_labels=None, causal_vars=None, var_type='snps', rand_state=5, calc_interpretability=False):\n",
    "    # Setup classifier - define model, the auc, and coefficients\n",
    "    implemented_list = ['log_reg', 'log_reg_cv', 'rand_forest', 'rand_forest_cv']\n",
    "    interp_auc = None\n",
    "    vscores = None\n",
    "\n",
    "    assert mod_type in implemented_list, 'check mod type: {}'.format(mod_type)\n",
    "    if mod_type == 'log_reg':\n",
    "        mlmod = LogisticRegression(penalty='l1', solver='liblinear', class_weight='balanced', \n",
    "                                   random_state=rand_state)\n",
    "        mlmod.fit(train_x, np.ravel(train_y)) \n",
    "        coefs = np.abs(mlmod.coef_) \n",
    "        \n",
    "    elif mod_type == 'log_reg_cv':\n",
    "        mlmod = LogisticRegressionCV(Cs=np.logspace(-4, -1.85, 80), penalty='l1', solver='liblinear', class_weight='balanced', \n",
    "                                   random_state=rand_state, cv=3, scoring = 'roc_auc',\n",
    "                                    ) #n_jobs=-1, #verbose=2\n",
    "        mlmod.fit(train_x, np.ravel(train_y)) \n",
    "        coefs = np.abs(mlmod.coef_) \n",
    "\n",
    "    elif mod_type =='rand_forest':\n",
    "        mlmod = RandomForestClassifier(class_weight='balanced', random_state=rand_state)\n",
    "        mlmod.fit(train_x, np.ravel(train_y)) \n",
    "        coefs = np.abs(mlmod.feature_importances_)\n",
    "        \n",
    "    elif mod_type == 'rand_forest_cv':\n",
    "        rfc = RandomForestClassifier(class_weight='balanced', random_state=rand_state)\n",
    "\n",
    "        # Declare a hyperparameter grid\n",
    "        # could try varying other RF hyperparameters as well\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [50, 100, 500],\n",
    "            \"max_depth\": [10, 50, None],\n",
    "            \"min_samples_leaf\": [1 ,25],\n",
    "        }\n",
    "\n",
    "        # Perform grid search, fit it, and print score\n",
    "        mlmod = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=3, scoring='roc_auc',\n",
    "                             ) #n_jobs=-1, verbose=2\n",
    "        mlmod.fit(train_x, np.ravel(train_y)) \n",
    "#         test_class_auc = mlmod.score(test_x, test_y)\n",
    "        coefs = np.abs(mlmod.best_estimator_.feature_importances_)\n",
    "    \n",
    "    test_class_auc = roc_auc_score(test_y, mlmod.predict_proba(test_x)[:, 1])\n",
    "\n",
    "    if calc_interpretability:\n",
    "        vscores = pd.DataFrame(zip(var_labels, np.ravel(coefs)), columns=['var', 'score']).set_index('var')\n",
    "        if causal_vars is not None:\n",
    "            _, interp_auc = calc_ROC(vscores, causal_vars)\n",
    "                  \n",
    "    ### Return vscores as well\n",
    "    return mlmod, test_class_auc, interp_auc, vscores\n",
    "\n",
    "def calc_ROC(df_scores, true_causal):\n",
    "    assert true_causal is not None, 'check true_causal list'\n",
    "\n",
    "    npips = len(df_scores)\n",
    "    all_vals = list(df_scores.index)\n",
    "    Pos = true_causal\n",
    "    Negs = set(all_vals) - set(Pos)\n",
    "\n",
    "    df_res = pd.DataFrame(columns=[\"TPR\", \"FPR\", \"FDR\", \"PWR\"], dtype=object) \n",
    "    df_scores.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "    \n",
    "    for i in range(1,npips+1):\n",
    "        v = df_scores[0:i].index\n",
    "        z = set(all_vals) -  set(v)\n",
    "        TP = len(set(v) & set(Pos))\n",
    "        FP = len(set(v)-set(Pos))\n",
    "        TN = len(set(z) & set(Negs))\n",
    "        FN = len(set(z)-set(Negs))\n",
    "        TPR = TP/(TP+FN)\n",
    "            \n",
    "        FPR = FP/(FP+TN) \n",
    "        FDR = FP/(FP+TP)\n",
    "        PWR = 1-(1-TPR)\n",
    "        df_res.loc[len(df_res)] = [TPR, FPR, FDR, PWR]\n",
    "        \n",
    "    auc = metrics.auc(np.array(df_res['FPR']), np.array(df_res['TPR']))\n",
    "    return df_res, auc\n",
    "\n",
    "def score_cv(model_type, X, y, true_causal=None, calc_interpretability=False, cv=5):\n",
    "    mods = []\n",
    "    class_aucs = []\n",
    "    interp_aucs = []\n",
    "    ### Keep track of vscores as well\n",
    "    vscores_l = []\n",
    "    \n",
    "    for i in range(cv):\n",
    "        train_x, test_x, train_y, test_y = split_data(X, y, rand_state=i) #check random state set\n",
    "        mlmod, test_class_auc, interp_auc, vscores = train_model(model_type, train_x, test_x, train_y, test_y, true_causal, calc_interpretability=calc_interpretability) \n",
    "\n",
    "        mods.append(mlmod)\n",
    "        class_aucs.append(test_class_auc)\n",
    "        interp_aucs.append(interp_auc)\n",
    "        vscores_l.append(vscores)\n",
    "        \n",
    "    return mods, class_aucs, interp_aucs, vscores_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eb37580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(dataset, simnum=None, most_variable=False):\n",
    "    '''Each dataset is (unfortunately) in sligtly different format; use function to get into numpy arrays\n",
    "    \n",
    "    Standardize to:\n",
    "    genome: np array of SNPs x patients\n",
    "    phenotype: np array of 0 (controls) and 1 (cases)\n",
    "    where the ordering of the patients in genome is identical to the ordering of the phenotype\n",
    "    '''\n",
    "    if dataset == 'als': #gzipped csvs\n",
    "        data_path = '/scratch/users/velina/sparse_nn/ltsim/data/als'\n",
    "        phenotype = load_data(data_path + '/EUR-AFR_y_labeled.csv').set_index('Unnamed: 0')\n",
    "        if most_variable:\n",
    "            genome = load_data(data_path + '/EUR-AFR_most_var_subset_100000_snps.csv.gz').set_index('Unnamed: 0')\n",
    "        else:\n",
    "            simnum = simnum - 1 # ltsim/epigen are 1 indexed while the real are 0 indexed; adjusted here.\n",
    "            genome = load_data(data_path + '/EUR-AFR_rand_subset_100000_snps_{}.csv.gz'.format(simnum)).set_index('Unnamed: 0')\n",
    "        assert (genome.columns == phenotype.index).all(), 'check ordering'\n",
    "        genome = genome.values\n",
    "        phenotype = (phenotype['label1']-1).values\n",
    "        \n",
    "    elif dataset == 'diabetes': # pkled pandas\n",
    "        data_path = '/scratch/users/velina/sparse_nn/t1d_data/snp_subset'\n",
    "        phenotype = load_data(data_path + '/y_labeled.csv').set_index('Unnamed: 0')\n",
    "        if most_variable:\n",
    "            genome = load_data(data_path + '/most_var_subset_100000_snps.p')\n",
    "        else:\n",
    "            simnum = simnum - 1 # ltsim/epigen are 1 indexed while the real are 0 indexed; adjusted here.\n",
    "            genome = load_data(data_path + '/rand_subset_100000_snps_{}.p'.format(simnum))\n",
    "        assert (genome.columns == phenotype.index).all(), 'check ordering'\n",
    "        genome = genome.values\n",
    "        phenotype = (phenotype['label1']-1).values\n",
    "        \n",
    "    elif dataset == 'epigen_pop2': # pkled numpys\n",
    "        data_path = '/scratch/users/divyar/epigen/sim/epigen_ceu_asw'\n",
    "        phenotype = load_data(data_path + '/ysim.{}.txt'.format(simnum))\n",
    "        genome = load_data(data_path + '/Xsim.{}.npy'.format(simnum))\n",
    "        \n",
    "    elif dataset == 'epigen_pop1':# pkled numpys\n",
    "        data_path = '/scratch/users/divyar/epigen/sim/epigen_ceu'\n",
    "        phenotype = load_data(data_path + '/ysim.{}.txt'.format(simnum))\n",
    "        genome = load_data(data_path + '/Xsim.{}.npy'.format(simnum))\n",
    "        \n",
    "    elif dataset == 'ltsim_pop1': #update with relevant path once final ltsim complete\n",
    "        data_path = '/scratch/users/aconard/sims/no_overlap/non_overlap_degree-4-ind-1e+06-tot_snp_sim-5000-frac_causal-0.1-k-0.1-obs-1500-maf_frac-0.05-pve-0.6-rho-0.5'\n",
    "        phenotype = load_data(data_path + '/ysim.{}.txt'.format(simnum))\n",
    "        phenotype = phenotype-1\n",
    "        genome = load_data(data_path + '/Xsim.{}.txt'.format(simnum)).T\n",
    "        \n",
    "    elif dataset == 'ltsim_pop2': #update with relevant path once final ltsim complete\n",
    "        data_path = '/scratch/users/aconard/sims/no_overlap/non_overlap_degree-4-ind-1e+06-tot_snp_sim-5000-frac_causal-0.1-k-0.1-obs-1500-maf_frac-0.05-pve-0.6-rho-0.5'\n",
    "        phenotype = load_data(data_path + '/ysim.{}.txt'.format(simnum))\n",
    "        phenotype = phenotype-1\n",
    "        genome = load_data(data_path + '/Xsim.{}.txt'.format(simnum)).T\n",
    "    else:\n",
    "        print('error loading files')\n",
    "    return phenotype, genome\n",
    "\n",
    "def load_data(filepath):\n",
    "    filepath = Path(filepath)\n",
    "    # load each datatype accordingly\n",
    "    if (filepath.suffix == '.gz') | (filepath.suffix == '.csv'):\n",
    "        file = pd.read_csv(filepath)\n",
    "    elif (filepath.suffix)=='.p':\n",
    "        file = joblib.load(filepath)\n",
    "    elif (filepath.suffix == '.npy'):\n",
    "        file = np.load(filepath)\n",
    "    elif filepath.suffix == '.txt':\n",
    "        file = np.loadtxt(filepath)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "als 1\n",
      "als (100000, 516) (516,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n",
      "als most_variable\n",
      "als (100000, 516) (516,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n",
      "diabetes 1\n",
      "diabetes (100000, 4901) (4901,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n",
      "diabetes most_variable\n",
      "diabetes (100000, 4901) (4901,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n",
      "epigen_pop1 1\n",
      "epigen_pop1 (100000, 5000) (5000,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n",
      "epigen_pop2 1\n",
      "epigen_pop2 (100000, 5000) (5000,)\n",
      "log_reg\n",
      "log_reg_cv\n",
      "rand_forest\n",
      "rand_forest_cv\n"
     ]
    }
   ],
   "source": [
    "df_model_results = pd.DataFrame()\n",
    "\n",
    "model_list = ['log_reg', 'log_reg_cv', 'rand_forest', 'rand_forest_cv']\n",
    "dataset_list = ['als', 'diabetes', 'epigen_pop1','epigen_pop2', 'ltsim_pop1']\n",
    "simnum_max = 2 # set to number of simulations want to be analyzed.\n",
    "\n",
    "for data in dataset_list:\n",
    "    srange = list(range(1,simnum_max))\n",
    "    if (data == 'als') | (data == 'diabetes'):\n",
    "        srange = srange + ['most_variable'] #if ALS or diabetes, include a most variable simulation.\n",
    "    for snum in srange:\n",
    "        print(data, snum)\n",
    "        if snum == 'most_variable':\n",
    "            variable=True\n",
    "        else:\n",
    "            variable=False\n",
    "        cpheno, cgenome = get_file(data, snum, most_variable=variable)\n",
    "        print(data, cgenome.shape, cpheno.shape)\n",
    "        train_x, test_x, train_y, test_y = split_data(cgenome.T, cpheno, rand_state=5)\n",
    "\n",
    "        for mod in model_list:\n",
    "            print(mod)\n",
    "            #If want epigen/ltsim interpretability, can update this and pass in true causal SNPs\n",
    "            true_causal=None\n",
    "            calc_interpretability=False \n",
    "            model_type=mod\n",
    "            mlmod, test_class_auc, interp_auc, vscores = train_model(model_type, train_x, test_x, train_y, test_y, \n",
    "                                                                     true_causal, calc_interpretability=calc_interpretability) \n",
    "            ncase = train_y.sum()+test_y.sum()\n",
    "            nctr = (len(train_y)+len(test_y))-ncase\n",
    "            dfnew = pd.DataFrame([{'data':data, 'mod':mod, 'sim':'sim_{}'.format(snum), 'test_auc':test_class_auc, 'num_cases': ncase, 'num_controls':nctr}])\n",
    "            df_model_results = pd.concat((df_model_results, dfnew), axis = 0, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfa86383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_forest_cv 0.4496124031007752 0.0\n"
     ]
    }
   ],
   "source": [
    "# # One testcase \n",
    "# mod_list = ['log_reg', 'log_reg_cv', 'rand_forest', 'rand_forest_cv']\n",
    "# ctrain_x, ctest_x, ctrain_y, ctest_y, csnp_labels = split_data(cX, cY, rand_state=4)\n",
    "\n",
    "# for model in mod_list:\n",
    "#     mmod, mcauc, miauc, mvscores = train_model(model, ctrain_x, ctest_x, ctrain_y, ctest_y) \n",
    "#     print(model, np.mean(mcauc), np.std(mcauc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
